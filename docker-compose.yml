name: opsseer
services:

  dockermeta:
    build:
      context: ./services/dockermeta
    container_name: dockermeta
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    ports:
      - "9101:9101"
    networks:
      - ops
    logging:
      driver: local
      options:
        max-size: "5m"
        max-file: "3"
  
  dockerstats:
    build:
      context: ./services/dockerstats
    container_name: dockerstats
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    ports:
      - "9102:9102"
    networks:
      - ops
    logging:
      driver: local
      options:
        max-size: "5m"
        max-file: "3"

  prometheus:
    image: prom/prometheus:v2.54.1
    container_name: prometheus
    command: ["--config.file=/etc/prometheus/prometheus.yml","--storage.tsdb.retention.time=2d","--web.enable-lifecycle"]
    volumes:
      - ./ops/prometheus:/etc/prometheus:ro
    ports: ["9090:9090"]
    depends_on: [alertmanager]
    networks: [ops]
    logging: { driver: "local", options: { max-size: "10m", max-file: "3" } }

  grafana:
    image: grafana/grafana:10.4.6
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
      - GF_SECURITY_ALLOW_EMBEDDING=true
      - GF_RENDERING_SERVER_URL=http://renderer:8081/render
      - GF_RENDERING_CALLBACK_URL=http://grafana:3000/
      - GF_LOG_FILTERS=rendering:debug
    volumes:
      - ./ops/grafana/provisioning:/etc/grafana/provisioning
    ports: ["3000:3000"]
    depends_on: [prometheus, renderer]
    networks: [ops]
    logging: { driver: "local", options: { max-size: "10m", max-file: "3" } }

  renderer:
    image: grafana/grafana-image-renderer:3.9.0
    container_name: renderer
    environment: [ "ENABLE_METRICS=true" ]
    ports: ["8081:8081"]
    networks: [ops]
    logging: { driver: "local", options: { max-size: "5m", max-file: "3" } }

  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: alertmanager
    command: ["--config.file=/etc/alertmanager/alertmanager.yml","--storage.path=/alertmanager"]
    volumes:
      - ./ops/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    ports: ["9093:9093"]
    networks: [ops]
    logging: { driver: "local", options: { max-size: "5m", max-file: "3" } }

  alertlogger:
    build: { context: ./services/alertlogger }
    container_name: alertlogger
    ports: ["9000:9000"]
    networks: [ops]
    logging: { driver: "local", options: { max-size: "5m", max-file: "3" } }

  toyprod:
    build: { context: ./services/toyprod }
    container_name: toyprod
    environment:
      - FAIL_RATE=0
      - BASE_DELAY_MS=0
    ports: ["8080:8000"]
    networks: [ops]
    logging: { driver: "local", options: { max-size: "5m", max-file: "3" } }
  
  asr:
    build:
      context: ./services/asr
    container_name: asr
    ports:
      - "8001:8000"
    networks:
      - ops
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    logging:
      driver: local
      options:
        max-size: "10m"
        max-file: "3"
  
  vision:
    build:
      context: ./services/vision
    container_name: vision
    ports:
      - "8002:8000"
    networks:
      - ops
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    logging:
      driver: local
      options:
        max-size: "10m"
        max-file: "3"

  docqa:
    build:
      context: ./services/docqa
    container_name: docqa
    volumes:
      - ./data/runbooks:/data/runbooks:ro
    ports:
      - "8003:8000"
    networks:
      - ops
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    logging:
      driver: local
      options:
        max-size: "10m"
        max-file: "3"
  
  ai-gateway:
    build:
      context: ./services/ai-gateway
    container_name: ai-gateway
    ports:
      - "8000:8000"
    networks:
      - ops
    logging:
      driver: local
      options:
        max-size: "10m"
        max-file: "3"
        
networks:
  ops:
    driver: bridge
